import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA  # Importando PCA

# ğŸ“Œ Carregar o dataset
df = pd.read_csv(r'C:\Users\Jhonatan\OneDrive\Ãrea de Trabalho\IA - Data Mining\Hotel Reservations.csv')

# ğŸ“Œ Verificar valores ausentes antes de criar a coluna de classificaÃ§Ã£o
df = df.dropna(subset=['avg_price_per_room'])

# ğŸ“Œ Criar a nova coluna 'label_avg_price_per_room'
df['label_avg_price_per_room'] = pd.cut(
    df['avg_price_per_room'], 
    bins=[-float('inf'), 85, 115, float('inf')],  
    labels=[1, 2, 3]
)

# ğŸ“Œ Remover valores NaN gerados e converter para inteiro
df = df.dropna(subset=['label_avg_price_per_room'])
df['label_avg_price_per_room'] = df['label_avg_price_per_room'].astype(int)

# ğŸ“Œ Remover colunas irrelevantes
df = df.drop(columns=['avg_price_per_room', 'Booking_ID', 'arrival_year', 'arrival_month', 'arrival_date'])

# ğŸ“Œ Converter variÃ¡veis categÃ³ricas para numÃ©ricas
df = pd.get_dummies(df)

# ğŸ“Œ Separar variÃ¡veis independentes (X) e dependentes (y)
X = df.drop(columns=['label_avg_price_per_room'])
y = df['label_avg_price_per_room']

# ğŸ“Œ Dividir os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# ğŸ“Œ Aplicar SMOTE para balancear os dados
smote = SMOTE(sampling_strategy='auto', random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

# ğŸ“Œ Normalizar os dados para SVM
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ğŸ“Œ Treinar o modelo SVM com kernel RBF e ajuste de hiperparÃ¢metros
svm_model_rbf = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)
svm_model_rbf.fit(X_train, y_train)

# ğŸ“Œ Fazer previsÃµes no conjunto de teste
y_pred_rbf = svm_model_rbf.predict(X_test)

# ğŸ“Œ Avaliar o modelo e exibir os resultados
accuracy_rbf = accuracy_score(y_test, y_pred_rbf)
print("ğŸ“¢ Resultados do SVM com Kernel RBF no dataset de HotÃ©is:")
print(f"âœ… PrecisÃ£o do modelo: {accuracy_rbf:.2f}\n")
print("ğŸ“Š RelatÃ³rio de classificaÃ§Ã£o:")
print(classification_report(y_test, y_pred_rbf, target_names=["PreÃ§o Baixo (1)", "PreÃ§o MÃ©dio (2)", "PreÃ§o Alto (3)"]))

# ğŸ“Š Exibir a matriz de confusÃ£o
plt.figure(figsize=(8, 6))
conf_matrix_rbf = confusion_matrix(y_test, y_pred_rbf)
sns.heatmap(conf_matrix_rbf, annot=True, fmt='d', cmap='Blues', xticklabels=["PreÃ§o Baixo (1)", "PreÃ§o MÃ©dio (2)", "PreÃ§o Alto (3)"], yticklabels=["PreÃ§o Baixo (1)", "PreÃ§o MÃ©dio (2)", "PreÃ§o Alto (3)"])
plt.title("Matriz de ConfusÃ£o - SVM com Kernel RBF")
plt.xlabel("PrediÃ§Ã£o")
plt.ylabel("Real")
plt.show()

# ğŸ“Š Visualizar a distribuiÃ§Ã£o de classes apÃ³s o balanceamento
plt.figure(figsize=(6, 4))
sns.countplot(x=y_train, palette="Set2")
plt.xlabel("Classe de PreÃ§o (Treinamento)")
plt.ylabel("Contagem")
plt.title("DistribuiÃ§Ã£o das Classes no Conjunto de Treinamento (ApÃ³s SMOTE)")
plt.show()

# ğŸ“Œ Aplicando PCA para reduzir para 2D (apenas para visualizaÃ§Ã£o)
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train)

# ğŸ“Š GrÃ¡fico de separaÃ§Ã£o das classes usando as duas primeiras componentes principais
plt.figure(figsize=(8, 6))
sns.scatterplot(x=X_train_pca[:, 0], y=X_train_pca[:, 1], hue=y_train, palette="Set2", s=100, edgecolor='black', marker='o')
plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.title("SeparaÃ§Ã£o das Classes de PreÃ§o (PCA com Kernel RBF)")
plt.show()

# ğŸ“Œ Exportar o dataset alterado
df.to_csv('Hotel_Reservations_Processed.csv', index=False)
