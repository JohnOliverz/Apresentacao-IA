import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from mlxtend.plotting import plot_decision_regions

# ğŸ“¥ Carregar o conjunto de dados IRIS
url = "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv"
df = pd.read_csv(url)

# ğŸ“Š Exibir a distribuiÃ§Ã£o das classes no dataset IRIS
plt.figure(figsize=(6, 4))
sns.countplot(x='species', data=df, palette="Set2")
plt.xlabel("Classe da EspÃ©cie")
plt.ylabel("Contagem")
plt.title("DistribuiÃ§Ã£o das Classes no Conjunto de Dados IRIS")
plt.show()

# ğŸ”„ Convertendo a coluna "species" para valores numÃ©ricos
label_encoder = LabelEncoder()
df['species'] = label_encoder.fit_transform(df['species'])

# ğŸ”  SeparaÃ§Ã£o das variÃ¡veis de entrada (X) e saÃ­da (y)
X = df.drop(columns=['species'])  # Remove a coluna de rÃ³tulo
y = df['species']  # Apenas os rÃ³tulos

# ğŸ“Š DivisÃ£o dos dados em treino e teste (80% treino, 20% teste)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# ğŸ”„ Normalizando os dados
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ğŸ” Aplicar PCA (reduÃ§Ã£o de dimensionalidade para 2 componentes principais)
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# ğŸ† Criando e treinando o modelo SVM com Kernel RBF
svm_model_rbf = SVC(kernel='rbf', C=1.0, gamma='scale')
svm_model_rbf.fit(X_train_pca, y_train)

# ğŸ” Fazer previsÃµes no conjunto de teste
y_pred_rbf = svm_model_rbf.predict(X_test_pca)

# ğŸ“Š AvaliaÃ§Ã£o do modelo
accuracy_rbf = accuracy_score(y_test, y_pred_rbf)
print("ğŸ“¢ Resultados do SVM com Kernel RBF e PCA no dataset IRIS:")
print(f"âœ… PrecisÃ£o do modelo: {accuracy_rbf:.2f}\n")

# Criando um dicionÃ¡rio para mapear os rÃ³tulos numÃ©ricos para nomes compreensÃ­veis
iris_classes = {i: label_encoder.classes_[i] for i in range(len(label_encoder.classes_))}

# ğŸ“Š Exibir relatÃ³rio de classificaÃ§Ã£o com nomes de classes personalizados
print("ğŸ“Š RelatÃ³rio de classificaÃ§Ã£o:")
print(classification_report(y_test, y_pred_rbf, target_names=[iris_classes[i] for i in range(3)]))

# ğŸ“Š Plotar a matriz de confusÃ£o
cm = confusion_matrix(y_test, y_pred_rbf)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris_classes.values(), yticklabels=iris_classes.values())
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.title("Matriz de ConfusÃ£o")
plt.show()

# ğŸ¨ Visualizar a fronteira de decisÃ£o com PCA (apenas 2D apÃ³s PCA)
plt.figure(figsize=(8, 6))
plot_decision_regions(X_train_pca, y_train.to_numpy(), clf=svm_model_rbf, legend=2)
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.title("SeparaÃ§Ã£o das Classes pelo SVM com Kernel RBF (apÃ³s PCA)")
plt.show()
