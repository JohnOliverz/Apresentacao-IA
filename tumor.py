import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.datasets import load_breast_cancer
from mlxtend.plotting import plot_decision_regions

# ğŸ“¥ Carregar o conjunto de dados Breast Cancer
cancer = load_breast_cancer()
df = pd.DataFrame(cancer.data, columns=cancer.feature_names)
df["target"] = cancer.target  # Adiciona a coluna de rÃ³tulos (0 ou 1)

# ğŸ“Š Visualizar a distribuiÃ§Ã£o das classes
plt.figure(figsize=(6, 4))
sns.countplot(x=df["target"], palette="Set2")
plt.xlabel("Classe do Tumor")
plt.ylabel("Contagem")
plt.title("DistribuiÃ§Ã£o das Classes do Conjunto de Dados Breast Cancer")
plt.show()

# ğŸ”„ Normalizando os dados
scaler = StandardScaler()
X = scaler.fit_transform(df.drop("target", axis=1))  # Normaliza os atributos
y = df["target"]

# ğŸ“Š DivisÃ£o dos dados em treino e teste (80% treino, 20% teste)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# ğŸ† Criando e treinando o modelo SVM com kernel linear
svm_model_linear = SVC(kernel='linear', C=1.0)  # Usando kernel linear
svm_model_linear.fit(X_train, y_train)

# ğŸ” Fazer previsÃµes no conjunto de teste
y_pred_svm = svm_model_linear.predict(X_test)

# ğŸ“Š AvaliaÃ§Ã£o do modelo
accuracy = accuracy_score(y_test, y_pred_svm)
print("ğŸ“¢ Resultados do SVM com Kernel Linear no dataset Breast Cancer:")
print(f"âœ… PrecisÃ£o do modelo: {accuracy:.2f}\n")

# ğŸ“Š RelatÃ³rio de classificaÃ§Ã£o
cancer_classes = {
    0: "Maligno",
    1: "Benigno"
}
print("ğŸ“Š RelatÃ³rio de classificaÃ§Ã£o:")
print(classification_report(y_test, y_pred_svm, target_names=[cancer_classes[i] for i in range(2)]))

# ğŸ“Œ Gerando a matriz de confusÃ£o
cm = confusion_matrix(y_test, y_pred_svm)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=cancer_classes.values(), yticklabels=cancer_classes.values())
plt.xlabel("Classe Predita")
plt.ylabel("Classe Real")
plt.title("Matriz de ConfusÃ£o - SVM com Kernel Linear")
plt.show()

# ğŸ“Š Visualizando a separaÃ§Ã£o das classes (para 2 caracterÃ­sticas apenas)
# Vamos usar apenas duas caracterÃ­sticas para a visualizaÃ§Ã£o da fronteira de decisÃ£o
X_train_vis = X_train[:, :2]  # Usando apenas as duas primeiras caracterÃ­sticas
X_test_vis = X_test[:, :2]

# ğŸ† Treinando o modelo novamente para visualizaÃ§Ã£o com as duas caracterÃ­sticas
svm_vis = SVC(kernel='linear', C=1.0)
svm_vis.fit(X_train_vis, y_train)

# ğŸ“Š GrÃ¡fico de separaÃ§Ã£o das classes usando as duas primeiras caracterÃ­sticas
plt.figure(figsize=(8, 6))
plot_decision_regions(X_train_vis, y_train.to_numpy(), clf=svm_vis, legend=2)  # ConversÃ£o de y_train para array NumPy
plt.xlabel(df.columns[0])
plt.ylabel(df.columns[1])
plt.title("SeparaÃ§Ã£o das Classes de Tumor (Kernel Linear - 2 CaracterÃ­sticas)")
plt.show()
